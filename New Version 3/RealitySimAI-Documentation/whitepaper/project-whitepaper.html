<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ver. 4 RealitySim AI: A Framework for Emergent AI Agent Simulation</title>
    <style>
        body {
            font-family: 'Roboto', 'Helvetica Neue', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            margin: 0;
            padding: 0;
            background-color: #f9f9f9;
        }
        .container {
            max-width: 900px;
            margin: 40px auto;
            background: #fff;
            padding: 30px 50px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.05);
        }
        h1, h2, h3, h4 {
            color: #2c3e50;
            margin-top: 1.5em;
            margin-bottom: 0.8em;
        }
        h1 {
            font-size: 2.5em;
            text-align: center;
            margin-bottom: 0.5em;
            color: #1a2a3a;
        }
        h2 {
            font-size: 1.8em;
            border-bottom: 2px solid #eee;
            padding-bottom: 0.5em;
        }
        h3 {
            font-size: 1.4em;
            color: #34495e;
        }
        p {
            margin-bottom: 1em;
            text-align: justify;
        }
        ul {
            list-style-type: disc;
            margin-left: 20px;
            margin-bottom: 1em;
        }
        ol {
            list-style-type: decimal;
            margin-left: 20px;
            margin-bottom: 1em;
        }
        .title-page {
            text-align: center;
            padding: 80px 0;
            border-bottom: 1px solid #eee;
            margin-bottom: 40px;
        }
        .title-page h1 {
            font-size: 3.5em;
            margin-bottom: 15px;
            color: #007bff;
        }
        .title-page p {
            font-size: 1.1em;
            color: #555;
            margin-bottom: 5px;
        }
        .mermaid {
            background-color: #f0f0f0;
            padding: 20px;
            border-radius: 5px;
            margin: 20px 0;
            overflow-x: auto;
            text-align: center;
        }
        code {
            background-color: #eef;
            padding: 2px 4px;
            border-radius: 3px;
            font-family: 'Fira Code', 'Consolas', 'Monaco', monospace;
            font-size: 0.9em;
        }
        pre {
            background-color: #eef;
            padding: 10px;
            border-radius: 5px;
            overflow-x: auto;
            font-family: 'Fira Code', 'Consolas', 'Monaco', monospace;
            font-size: 0.9em;
        }
        .section-header {
            margin-top: 40px;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 2px solid #007bff;
            color: #007bff;
            font-size: 1.6em;
            font-weight: bold;
        }
        .appendix-item {
            margin-bottom: 0.5em;
        }
        .glossary-term {
            font-weight: bold;
            color: #007bff;
        }
    </style>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({startOnLoad: true, theme: 'neutral'});
    </script>
</head>
<body>
    <div class="container">
        <div class="title-page">
            <h1>Ver. 4 RealitySim AI</h1>
            <p>A Framework for Emergent AI Agent Simulation</p>
            <p>Version: 1.0</p>
            <p>Release Date: 2025-08-02</p>
            <p>Author(s): Mermaid Architect AI</p>
            <p>License: MIT License</p>
            <p><a href="https://github.com/google/ai-studio-app-template" target="_blank">Source Code Repository (Template Base)</a></p>
        </div>

        <h2 class="section-header">2. Executive Summary</h2>
        <p>
            The Ver. 4 RealitySim AI project presents an interactive, web-based simulation environment designed for the study of emergent cognitive and social behaviors in artificial intelligence agents. It provides a dynamic world where AI agents, endowed with distinct beliefs, memories, and personalities, interact autonomously. The system enables users to control simulation progression, introduce new elements, and visualize complex inter-agent relationships and environmental changes in real-time.
        </p>
        <p>
            This framework was developed to address the limitations of static AI models by offering a platform for observing and analyzing the adaptive and evolving behaviors of AI in a dynamic, multi-agent context. It serves researchers, developers, and educators interested in AI ethics, social dynamics, and the development of more nuanced and adaptable AI systems, providing a transparent and controllable sandbox for experimentation.
        </p>

        <h2 class="section-header">3. Problem Statement</h2>
        <p>
            Current approaches to AI development often focus on isolated task performance or single-agent environments, neglecting the complexities of multi-agent interaction and emergent system-level behaviors. Traditional simulation tools frequently lack the flexibility for dynamic, natural language-driven agent control and real-time visualization of internal agent states (e.g., beliefs, emotions, relationships). This deficit hinders the comprehensive understanding of how AI agents adapt, learn, and interact within complex social and economic structures, and how their internal states influence their external actions. There is a critical need for a platform that facilitates the observation and manipulation of these emergent properties, enabling researchers to explore the societal implications and ethical considerations of advanced AI systems in a controlled, observable manner.
        </p>

        <h2 class="section-header">4. System Architecture and Functionality</h2>
        <p>
            The Ver. 4 RealitySim AI system employs a client-side, React-based architecture, emphasizing modularity and reactive state management. The core application logic resides within the central <code>App</code> component, which acts as the primary orchestrator of the simulation's state and user interface.
        </p>

        <h3>Architectural Diagram</h3>
        <div class="mermaid">sequenceDiagram
    participant User
    participant Browser
    participant index.tsx as AppEntry
    participant App
    participant LanguageContext
    participant SettingsContext
    participant LocalStorage
    participant ControlPanel
    participant CreateObjectPanel
    participant AdminPanel
    participant ExporterPanel
    participant WorldGraph
    participant LogPanel
    participant BeliefsChart
    participant ProcessingIndicator
    participant useTranslations
    participant SimulationEngine
    participant AI_Model

    Browser-&gt;&gt;AppEntry: Load index.html
    AppEntry-&gt;&gt;LanguageContext: Initialize Provider
    AppEntry-&gt;&gt;SettingsContext: Initialize Provider
    SettingsContext-&gt;&gt;LocalStorage: Read stored settings
    LocalStorage--&gt;&gt;SettingsContext: Return settings
    AppEntry-&gt;&gt;App: Render main application
    App-&gt;&gt;ControlPanel: Render
    App-&gt;&gt;CreateObjectPanel: Render
    App-&gt;&gt;AdminPanel: Render
    App-&gt;&gt;ExporterPanel: Render
    App-&gt;&gt;WorldGraph: Render (initial empty state)
    App-&gt;&gt;LogPanel: Render (initial empty state)
    App-&gt;&gt;BeliefsChart: Render (initial empty state)

    User-&gt;&gt;ControlPanel: Click "Generate World"
    ControlPanel-&gt;&gt;App: onGenerateWorld()
    App-&gt;&gt;ProcessingIndicator: Show processing overlay
    App-&gt;&gt;SimulationEngine: generateInitialWorldState()
    SimulationEngine-&gt;&gt;AI_Model: Request initial world/agent data
    AI_Model--&gt;&gt;SimulationEngine: Return generated data
    SimulationEngine--&gt;&gt;App: Return initial WorldState
    App-&gt;&gt;App: Update WorldState
    App-&gt;&gt;ProcessingIndicator: Hide processing overlay
    App-&gt;&gt;WorldGraph: Pass WorldState (agents, entities, env, cultures)
    App-&gt;&gt;LogPanel: Pass logs
    App-&gt;&gt;BeliefsChart: Pass agent beliefs

    loop Simulation Steps
        User-&gt;&gt;ControlPanel: Click "Step" or "Run"
        ControlPanel-&gt;&gt;App: onStep() / onRunSteps(N)
        App-&gt;&gt;ProcessingIndicator: Show processing overlay
        App-&gt;&gt;SimulationEngine: executeSimulationStep(currentWorldState)
        SimulationEngine-&gt;&gt;SimulationEngine: For each Agent:
        SimulationEngine-&gt;&gt;AI_Model: Request next action/decision
        AI_Model--&gt;&gt;SimulationEngine: Return chosen action
        SimulationEngine-&gt;&gt;SimulationEngine: Execute Action.execute() (updates WorldState)
        SimulationEngine--&gt;&gt;App: Return updated WorldState & LogEntries
        App-&gt;&gt;App: Update WorldState, append LogEntries
        App-&gt;&gt;ProcessingIndicator: Hide processing overlay
        App-&gt;&gt;WorldGraph: Pass updated WorldState
        App-&gt;&gt;LogPanel: Pass updated logs
        App-&gt;&gt;BeliefsChart: Pass updated agent beliefs
    end

    User-&gt;&gt;CreateObjectPanel: Fill form & Click "Create"
    CreateObjectPanel-&gt;&gt;App: onCreate(type, data)
    App-&gt;&gt;App: Add new object to WorldState
    App-&gt;&gt;WorldGraph: Pass updated WorldState

    User-&gt;&gt;AdminPanel: Modify agent health / Enact Law
    AdminPanel-&gt;&gt;App: onSetAgentHealth() / onEnactLaw()
    App-&gt;&gt;App: Update WorldState
    App-&gt;&gt;WorldGraph: Pass updated WorldState

    User-&gt;&gt;ExporterPanel: Click "Save All"
    ExporterPanel-&gt;&gt;App: onExport('all')
    App-&gt;&gt;LocalStorage: Save current WorldState

    User-&gt;&gt;ExporterPanel: Click "Load"
    ExporterPanel-&gt;&gt;App: onLoad()
    App-&gt;&gt;LocalStorage: Load WorldState
    LocalStorage--&gt;&gt;App: Return loaded WorldState
    App-&gt;&gt;App: Set WorldState
    App-&gt;&gt;WorldGraph: Pass loaded WorldState
    App-&gt;&gt;LogPanel: Pass loaded logs
    App-&gt;&gt;BeliefsChart: Pass loaded agent beliefs

    User-&gt;&gt;LanguageSwitcher: Click language button
    LanguageSwitcher-&gt;&gt;LanguageContext: setLanguage(newLang)
    LanguageContext-&gt;&gt;useTranslations: Language changed event
    useTranslations--&gt;&gt;ControlPanel: Trigger re-render
    useTranslations--&gt;&gt;CreateObjectPanel: Trigger re-render
    useTranslations--&gt;&gt;AdminPanel: Trigger re-render
    useTranslations--&gt;&gt;ExporterPanel: Trigger re-render
    useTranslations--&gt;&gt;WorldGraph: Trigger re-render
    useTranslations--&gt;&gt;LogPanel: Trigger re-render
    useTranslations--&gt;&gt;BeliefsChart: Trigger re-render
    useTranslations--&gt;&gt;ProcessingIndicator: Trigger re-render</div>

        <h3>Technical Implementation and Data Flow</h3>
        <p>
            The application initializes in <code>index.tsx</code>, establishing global contexts for language and settings. The <code>SettingsContext</code> leverages <code>LocalStorage</code> for persistence of user preferences, including AI model provider and API configurations. The primary <code>App</code> component then renders, managing the global <code>WorldState</code>, which encompasses <code>EnvironmentState</code>, <code>Agent</code> data, <code>Entity</code> data, <code>Action</code> definitions, <code>Culture</code> and <code>Religion</code> information, and newly introduced economic and political structures like <code>Government</code>, <code>Market</code>, and <code>Technology</code> trees.
        </p>
        <p>
            User interactions are primarily mediated through dedicated control panels:
            <ul>
                <li><code>ControlPanel</code>: Facilitates core simulation commands such as advancing steps (<code>onStep</code>, <code>onRunSteps</code>), resetting the simulation (<code>onReset</code>), and generating initial world content (<code>onGenerateWorld</code>, <code>onGenerateContent</code>). These actions delegate to the <code>App</code>, which then interacts with an implied <code>SimulationEngine</code>.</li>
                <li><code>CreateObjectPanel</code>: Allows for the dynamic introduction of new <code>Agent</code>, <code>Entity</code>, or <code>Action</code> instances into the simulation, providing configurable parameters like beliefs, genome, role, and personality for agents.</li>
                <li><code>AdminPanel</code>: Offers granular control over simulation parameters and agent properties, including health, currency, position, and the ability to enact or repeal laws, start elections, and manage technological advancements within cultures.</li>
                <li><code>ExporterPanel</code>: Manages state persistence, enabling users to save and load the entire <code>WorldState</code> or specific subsets (environment, agents, entities) to/from <code>LocalStorage</code>.</li>
            </ul>
        </p>
        <p>
            The <code>SimulationEngine</code> (an implied module within the <code>App</code>'s logic) is responsible for processing each simulation step. During a step, it iterates through active agents, querying an external <code>AI_Model</code> (via the <code>@google/genai</code> library) to determine agent behaviors based on their current state, beliefs, relationships, and environmental context. This interaction with the AI model is critical for emergent behavior. The <code>AI_Model</code>'s responses drive updates to the <code>WorldState</code>, including agent positions, inventory changes, relationship dynamics, and the generation of <code>LogEntry</code> events.
        </p>
        <p>
            Visual components react dynamically to changes in the <code>WorldState</code>:
            <ul>
                <li><code>WorldGraph</code>: Renders the spatial layout of agents and entities, visualizing relationships and cultural affiliations. Icons for entities (e.g., resources, marketplaces, jails) and agents (with roles and health indicators) provide immediate visual feedback.</li>
                <li><code>LogPanel</code>: Displays a chronological stream of simulation events, providing a textual record of agent actions and world changes.</li>
                <li><code>BeliefsChart</code>: Utilizes <code>recharts</code> to visualize agent belief networks, offering insights into the internal cognitive states driving agent behavior.</li>
            </ul>
        </p>
        <p>
            Multi-language support is provided by the <code>LanguageContext</code> and the <code>useTranslations</code> hook, ensuring all UI elements and log messages can be localized. A <code>ProcessingIndicator</code> provides visual feedback during computationally intensive operations, such as world generation or multi-step simulations, enhancing user experience.
        </p>

        <h2 class="section-header">5. Evaluation and Test Results</h2>
        <p>
            The success of the Ver. 4 RealitySim AI system is primarily evaluated through its capacity to facilitate the observation and analysis of complex emergent behaviors, its stability under prolonged operation, and its responsiveness to user interaction.
        </p>

        <h3>Qualitative Assessment</h3>
        <ul>
            <li><strong>Robustness:</strong> The system's architecture, leveraging React's component-based structure and explicit state management, contributes to its robustness. Type definitions (<code>types.ts</code>) enforce data consistency, reducing runtime errors. The use of <code>LocalStorage</code> for state persistence ensures that simulation progress can be saved and restored, mitigating data loss from browser sessions. Error handling for AI model interactions (e.g., <code>try-catch</code> blocks for JSON parsing in <code>CreateObjectPanel</code>) enhances stability.</li>
            <li><strong>Performance/Speed:</strong> Performance is largely dependent on the computational load of the <code>SimulationEngine</code> and the latency of the external <code>AI_Model</code>. For client-side operations, React's virtual DOM and memoization (e.g., <code>React.useMemo</code> in <code>BeliefsChart</code> for translated data) optimize rendering performance. The <code>ProcessingIndicator</code> effectively manages user expectations during AI inference or multi-step runs. While not explicitly benchmarked, the design allows for parallel processing of agent decisions, which could be exploited for performance gains in future iterations.</li>
            <li><strong>Usability (UX):</strong> The user interface is designed for intuitive interaction. The <code>ControlPanel</code> provides clear actions for simulation progression. The visual components (<code>WorldGraph</code>, <code>LogPanel</code>, <code>BeliefsChart</code>) offer immediate and comprehensive insights into the simulation state. Features like the <code>CreateObjectPanel</code> and <code>AdminPanel</code> provide powerful, yet accessible, tools for manipulating the simulation. Multi-language support via <code>LanguageSwitcher</code> and <code>useTranslations</code> enhances accessibility for a broader user base.</li>
        </ul>
        <p>
            No formal metrics or benchmarks are currently integrated into the provided codebase. Evaluation of emergent behaviors is primarily qualitative, relying on visual inspection of the <code>WorldGraph</code>, analysis of the <code>LogPanel</code>, and interpretation of agent beliefs and relationships.
        </p>

        <h2 class="section-header">6. Comparison with Other Tools</h2>
        <p>
            The Ver. 4 RealitySim AI project distinguishes itself from general-purpose diagramming tools (e.g., PlantUML for architecture, Doxygen for code documentation) and traditional agent-based modeling (ABM) platforms (e.g., NetLogo, GAMA) through its specific focus on interactive, natural language-driven AI agent simulation within a web-based environment.
        </p>
        <h3>Differentiators:</h3>
        <ul>
            <li><strong>Direct LLM Integration:</strong> Unlike most ABM platforms that rely on predefined rule sets or statistical models for agent behavior, RealitySim AI directly integrates with large language models (LLMs) like Google Gemini (via <code>@google/genai</code>). This enables agents to exhibit more nuanced, context-aware, and human-like decision-making and interaction, driven by natural language prompts, rather than rigid programmatic logic.</li>
            <li><strong>Real-time Interactive Control:</strong> The React-based web interface provides real-time visualization and direct manipulation of the simulation. Users can dynamically add agents, entities, modify agent attributes, enact laws, and observe immediate consequences, which is less common in batch-oriented or desktop-bound ABM tools.</li>
            <li><strong>Rich Agent State Representation:</strong> The <code>types.ts</code> file defines a comprehensive agent model, including complex attributes like <code>Beliefs</code>, <code>Emotions</code>, <code>Personality</code>, <code>SocialMemory</code>, <code>Goals</code>, <code>Trauma</code>, and economic properties (<code>currency</code>, <code>inventory</code>). This depth allows for the simulation of highly detailed psychological and social dynamics, exceeding the typical scope of simpler ABM frameworks.</li>
            <li><strong>Emergent Socio-Economic Systems:</strong> The inclusion of explicit types for <code>Market</code>, <code>Law</code>, <code>Government</code>, and <code>Technology</code> allows for the emergence and study of complex socio-economic and political systems, which is a specialized feature not universally found in general ABM tools.</li>
            <li><strong>Accessibility and Deployment:</strong> Being a web application, RealitySim AI is inherently more accessible, requiring only a modern web browser to run. This contrasts with desktop applications that might require specific operating systems or complex installation procedures.</li>
        </ul>
        <p>
            While tools like NetLogo excel in pedagogical clarity for basic ABM concepts, they typically lack the advanced LLM integration and dynamic, rich agent state management present in RealitySim AI. Similarly, Doxygen and PlantUML are documentation tools, not simulation environments, serving entirely different purposes. RealitySim AI's unique selling proposition lies in its fusion of sophisticated AI agent modeling with an interactive, accessible web platform for studying complex emergent behaviors.
        </p>

        <h2 class="section-header">7. Core Concepts and Innovations</h2>
        <p>
            The Ver. 4 RealitySim AI project introduces several core concepts and innovations that enhance the study of artificial intelligence in dynamic, multi-agent environments:
        </p>
        <ul>
            <li><strong>LLM-Driven Agent Cognition:</strong> The most significant innovation is the direct integration of large language models (LLMs) as the primary cognitive engine for AI agents. Instead of relying on hard-coded decision trees or simple rule-based systems, agents query an LLM (e.g., Google Gemini) to determine their actions, interpret the world, and engage in social interactions. This allows for highly flexible, context-aware, and emergent behaviors that are difficult to pre-program. The <code>AI_Model</code> abstraction facilitates this interaction, allowing for different LLM providers.</li>
            <li><strong>Comprehensive Agent State Model:</strong> The <code>Agent</code> interface in <code>types.ts</code> defines a rich and multifaceted representation of an individual agent, incorporating psychological (<code>beliefNetwork</code>, <code>emotions</code>, <code>personality</code>, <code>goals</code>, <code>trauma</code>), social (<code>socialMemory</code>, <code>relationships</code>, <code>cultureId</code>, <code>religionId</code>), physical (<code>health</code>, <code>hunger</code>, <code>thirst</code>, <code>fatigue</code>), and economic (<code>currency</code>, <code>inventory</code>, <code>skills</code>) attributes. This holistic model enables the simulation of complex, human-like motivations and responses.</li>
            <li><strong>Dynamic World Evolution:</strong> The simulation is not static. Beyond agent interactions, the <code>WorldState</code> includes dynamic elements like <code>Government</code> (with mutable <code>laws</code> and <code>elections</code>), <code>Markets</code> (with <code>TradeOffer</code>s), and a <code>TechTree</code>. This allows for the study of how agent actions collectively shape the world's political, economic, and technological landscape, leading to macro-level emergent phenomena.</li>
            <li><strong>Interactive and Observable Simulation:</strong> The React-based frontend provides real-time visualization and direct manipulation capabilities. Users can observe agent positions, relationships, and internal states (via <code>BeliefsChart</code>) as the simulation progresses. The ability to inject new agents, entities, or modify world parameters mid-simulation offers a powerful research and debugging tool for understanding complex system dynamics.</li>
            <li><strong>Multi-Language Support:</strong> The integrated <code>LanguageContext</code> and <code>useTranslations</code> hook demonstrate a commitment to accessibility and broader applicability, allowing the simulation interface and logs to be presented in different languages.</li>
        </ul>
        <p>
            The fundamental design philosophy is to create an observable sandbox where the emergent properties of complex adaptive systems, driven by advanced AI cognition, can be studied and understood. The innovation lies in the depth of agent modeling combined with the dynamic world and the direct, interactive influence of LLMs on agent behavior.
        </p>

        <h2 class="section-header">8. Future Work and Outlook</h2>
        <p>
            The Ver. 4 RealitySim AI project lays a robust foundation for advanced AI agent simulation. Future work will focus on expanding the depth and complexity of the simulation, enhancing the realism of agent behaviors, and improving the analytical capabilities of the platform.
        </p>
        <h3>Potential Enhancements:</h3>
        <ul>
            <li><strong>Advanced Economic Models:</strong> Implement more sophisticated economic models, including supply-demand dynamics, inflation, and agent-driven production chains for crafted items.</li>
            <li><strong>Ecosystem Dynamics:</strong> Introduce environmental factors such as climate, natural disasters, and resource regeneration, allowing agents to interact with and adapt to a changing ecosystem.</li>
            <li><strong>Learning and Adaptation:</strong> Develop mechanisms for agents to learn from past experiences, adapt their beliefs and behaviors, and transmit knowledge across generations or cultures. This could involve more sophisticated memory systems or reinforcement learning integration.</li>
            <li><strong>Complex Social Structures:</strong> Expand the political and social systems to include factions, diplomacy, warfare, and more intricate governance models beyond simple leadership and laws.</li>
            <li><strong>Improved AI Model Integration:</strong> Explore fine-tuning LLMs for specific agent roles or behaviors, or integrating multiple specialized AI models (e.g., for pathfinding, strategic planning, emotional reasoning).</li>
            <li><strong>Performance Optimization:</strong> For larger-scale simulations, investigate Web Workers for offloading heavy computation, or explore server-side simulation execution for massive multi-agent scenarios.</li>
            <li><strong>Data Analysis and Visualization Tools:</strong> Develop more advanced tools for quantitative analysis of simulation data, including statistical dashboards, trend analysis, and network visualization for social graphs.</li>
            <li><strong>Genetic Algorithms and Evolution:</strong> Implement a genetic algorithm framework where agent genomes influence traits and behaviors, allowing for the simulation of evolutionary pressures and the emergence of new species or societal structures.</li>
        </ul>
        <p>
            The long-term vision for RealitySim AI is to become a leading platform for research into AI ethics, societal AI, and the co-evolution of AI and human-like systems. It could serve as a testbed for studying the impact of AI on economies, political systems, and cultural development, providing valuable insights for policy-makers, ethicists, and AI developers.
        </p>

        <h2 class="section-header">9. Conclusion</h2>
        <p>
            The Ver. 4 RealitySim AI project represents a significant step towards creating an interactive, observable, and dynamic environment for simulating complex AI agent behaviors. By integrating large language models as the cognitive core of its agents and providing a rich, extensible <code>WorldState</code>, the platform enables the study of emergent social, economic, and political phenomena. Its modular React-based architecture, coupled with intuitive control and visualization tools, makes it a valuable asset for researchers and developers exploring the frontiers of multi-agent AI systems. RealitySim AI offers a unique sandbox for understanding the intricate interplay between individual agent cognition and collective system-level dynamics, paving the way for more responsible and insightful AI development.
        </p>

        <h2 class="section-header">10. Appendix (References and Glossary)</h2>
        <h3>References/Sources:</h3>
        <ul>
            <li class="appendix-item"><strong>React:</strong> A JavaScript library for building user interfaces. <a href="https://react.dev/" target="_blank">https://react.dev/</a></li>
            <li class="appendix-item"><strong>Recharts:</strong> A composable charting library built on React components. <a href="https://recharts.org/" target="_blank">https://recharts.org/</a></li>
            <li class="appendix-item"><strong>Google GenAI SDK:</strong> Official JavaScript SDK for Google's generative AI models. <a href="https://github.com/google/generative-ai-js" target="_blank">https://github.com/google/generative-ai-js</a></li>
            <li class="appendix-item"><strong>Mermaid.js:</strong> Diagramming and charting tool that renders Markdown-inspired text definitions into diagrams. <a href="https://mermaid.js.org/" target="_blank">https://mermaid.js.org/</a></li>
            <li class="appendix-item"><strong>Vite:</strong> A fast frontend build tool. <a href="https://vitejs.dev/" target="_blank">https://vitejs.dev/</a></li>
            <li class="appendix-item"><strong>Tailwind CSS:</strong> A utility-first CSS framework. <a href="https://tailwindcss.com/" target="_blank">https://tailwindcss.com/</a></li>
        </ul>

        <h3>Glossary:</h3>
        <ul>
            <li class="appendix-item"><span class="glossary-term">Agent:</span> An autonomous entity within the simulation, possessing unique beliefs, memories, personality, and capable of independent action and interaction.</li>
            <li class="appendix-item"><span class="glossary-term">AI_Model:</span> An external Large Language Model (LLM) service (e.g., Google Gemini) used by the SimulationEngine to determine agent decisions and generate content.</li>
            <li class="appendix-item"><span class="glossary-term">Beliefs:</span> A quantitative representation of an agent's convictions or understanding about various concepts within the world.</li>
            <li class="appendix-item"><span class="glossary-term">Culture:</span> A group of agents sharing common beliefs, technologies, and potentially research progress.</li>
            <li class="appendix-item"><span class="glossary-term">Entity:</span> A non-agent object within the simulation environment, such as resources, buildings, marketplaces, or jails.</li>
            <li class="appendix-item"><span class="glossary-term">Emergent Behavior:</span> Complex patterns or properties that arise from the interactions of individual agents or components within a system, not explicitly programmed into any single component.</li>
            <li class="appendix-item"><span class="glossary-term">LLM (Large Language Model):</span> A type of artificial intelligence model trained on vast amounts of text data, capable of understanding, generating, and responding to human language.</li>
            <li class="appendix-item"><span class="glossary-term">LocalStorage:</span> A web storage API that allows web applications to store data persistently in the browser, without an expiration date.</li>
            <li class="appendix-item"><span class="glossary-term">Relationship:</span> A dynamic connection between two agents, characterized by type (e.g., friend, rival) and a score reflecting its strength or nature.</li>
            <li class="appendix-item"><span class="glossary-term">SimulationEngine:</span> The logical core responsible for advancing the simulation state, processing agent actions, and updating the world based on agent decisions and environmental rules.</li>
            <li class="appendix-item"><span class="glossary-term">WorldState:</span> The comprehensive data structure representing the entire current state of the simulation, including all agents, entities, environmental parameters, and global structures.</li>
        </ul>
    </div>
</body>
</html>